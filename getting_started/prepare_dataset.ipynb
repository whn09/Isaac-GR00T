{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730f711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28728584",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet = pd.read_parquet('demo_data/so100_strawberry_grape/data/chunk-000/episode_000000.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c89d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96265f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet['action'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fa5b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet['observation.state'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912b0f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet1 = pd.read_parquet('demo_data/so100_strawberry_grape/data/chunk-000/episode_000001.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b21092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fcd8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet39 = pd.read_parquet('demo_data/so100_strawberry_grape/data/chunk-000/episode_000039.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62a15b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4d2b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir -p demo_data/elephant_robot/\n",
    "# !mkdir -p demo_data/elephant_robot/data/chunk-000\n",
    "# !mkdir -p demo_data/elephant_robot/meta\n",
    "# !mkdir -p demo_data/elephant_robot/videos/chunk-000/observation.images.webcam\n",
    "# !cp demo_data/so100_strawberry_grape/meta/* demo_data/elephant_robot/meta/\n",
    "# # Change the json files in `demo_data/elephant_robot/meta/`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a898932",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dd2eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('demo_data/elephant_robot/夹取端子训练.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19afe2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fc30f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义要合并的列名\n",
    "array_columns = [\"左臂关节数据\", \"右臂关节数据\"]\n",
    "numeric_columns = [\"左臂力控夹爪位置\", \"右臂力控夹爪位置\"]\n",
    "\n",
    "# 解析字符串形式的数组\n",
    "def parse_array_string(array_str):\n",
    "    if pd.isna(array_str):\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        # 尝试使用ast.literal_eval解析(更安全)\n",
    "        return ast.literal_eval(array_str)\n",
    "    except (ValueError, SyntaxError):\n",
    "        try:\n",
    "            # 尝试使用json.loads解析\n",
    "            return json.loads(array_str)\n",
    "        except json.JSONDecodeError:\n",
    "            # 如果两种方法都失败，尝试简单的字符串处理\n",
    "            cleaned_str = array_str.strip('[]').split(',')\n",
    "            return [float(x.strip()) for x in cleaned_str if x.strip()]\n",
    "    except:\n",
    "        # 所有方法都失败时返回空列表\n",
    "        return []\n",
    "\n",
    "def merge_data(row):\n",
    "    result = []\n",
    "    \n",
    "    # 添加数组类型数据\n",
    "    for col in array_columns:\n",
    "        if isinstance(row[col], list):\n",
    "            result.extend(row[col])\n",
    "        elif isinstance(row[col], np.ndarray):\n",
    "            result.extend(row[col].tolist())\n",
    "        elif isinstance(row[col], str):\n",
    "            array_data = parse_array_string(row[col])\n",
    "            result.extend(array_data)\n",
    "        # 处理可能的NaN值\n",
    "        elif pd.isna(row[col]):\n",
    "            pass  # 或者添加一些默认值\n",
    "    \n",
    "    # 添加数字类型数据\n",
    "    for col in numeric_columns:\n",
    "        if not pd.isna(row[col]):  # 确保不是NaN\n",
    "            result.append(row[col])\n",
    "    \n",
    "    if len(result) != 16:\n",
    "        print(len(result))\n",
    "        print(row)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128cb9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.ffill()  # 填充部分空数据\n",
    "data['observation.state'] = data.apply(merge_data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f71406",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4717cd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['task_index'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61b4e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('demo_data/elephant_robot/夹取端子训练.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# 解析时间戳\n",
    "timestamps = []\n",
    "for line in lines:\n",
    "    try:\n",
    "        end_time = float(line.strip())\n",
    "        timestamps.append(end_time)\n",
    "    except ValueError:\n",
    "        print(f\"警告：无法解析时间戳 '{line.strip()}'，已跳过\")\n",
    "\n",
    "# 确保时间戳是按顺序排列的\n",
    "timestamps.sort()\n",
    "\n",
    "print(timestamps)\n",
    "\n",
    "# 将秒转换为毫秒\n",
    "timestamps_ms = [t * 1000 for t in timestamps]\n",
    "print(timestamps_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0983340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个函数来确定每行数据属于哪个episode\n",
    "def assign_episode(time_ms):\n",
    "    # 为时间戳添加起始值0\n",
    "    all_timestamps = [0] + timestamps_ms\n",
    "    \n",
    "    for i in range(len(all_timestamps)-1):\n",
    "        if all_timestamps[i] <= time_ms < all_timestamps[i+1]:\n",
    "            return i\n",
    "    \n",
    "    # 如果时间超过最后一个时间戳，归入最后一个episode\n",
    "    return len(all_timestamps) - 1\n",
    "\n",
    "# 应用函数创建episode列\n",
    "data['episode_index'] = data['时间间隔'].cumsum().apply(assign_episode)\n",
    "\n",
    "data['index'] = list(range(data.shape[0]))\n",
    "\n",
    "# 将DataFrame拆分成多个episode\n",
    "episodes = {}\n",
    "for episode_num in range(len(timestamps) + 1):  # +1 是因为包括timestamps之后的数据\n",
    "    episodes[episode_num] = data[data['episode_index'] == episode_num].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2079b65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b24c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for episode_num in range(len(timestamps) + 1):\n",
    "    print(episodes[episode_num].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedd907e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_actions(episode_df):\n",
    "    # 假设\"合并数据\"列包含了完整state\n",
    "    states = np.array(episode_df[\"observation.state\"].tolist())\n",
    "    \n",
    "    # 计算相邻时间步的状态差作为动作\n",
    "    # 使用t+1时刻减去t时刻的状态\n",
    "    actions = states[1:] - states[:-1]\n",
    "    \n",
    "    # 第一个时间步没有前一状态，可以填充为零或NaN\n",
    "    first_action = np.zeros_like(actions[0]) if len(actions) > 0 else np.array([])\n",
    "    all_actions = np.vstack([first_action, actions]) if len(actions) > 0 else np.array([first_action])\n",
    "    \n",
    "    return all_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5b9bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 为每个episode计算动作\n",
    "for episode_num, episode_df in episodes.items():\n",
    "    actions = compute_actions(episode_df)\n",
    "    episodes[episode_num][\"action\"] = list(actions)\n",
    "    \n",
    "    time_intervals = episode_df[\"时间间隔\"].values\n",
    "    time_intervals[0] = 0\n",
    "    cumulative_time_ms = np.cumsum(time_intervals)  # 计算累积和（毫秒）\n",
    "    episodes[episode_num][\"timestamp\"] = cumulative_time_ms / 1000.0\n",
    "    \n",
    "    # episodes[episode_num][\"frame_index\"] = list(range(episode_df.shape[0]))\n",
    "    \n",
    "    timestamps = episodes[episode_num][\"timestamp\"].values\n",
    "        \n",
    "    # 检测时间间隙(超过1.5倍正常帧间隔)\n",
    "    fps = 30\n",
    "    frame_interval = 1.0/fps\n",
    "    time_diffs = np.diff(timestamps)\n",
    "    gaps = np.where(time_diffs > 1.5 * frame_interval)[0]\n",
    "    \n",
    "    if len(gaps) > 0:\n",
    "        print(f\"Episode {episode_num} 包含 {len(gaps)} 个时间间隙\")\n",
    "        \n",
    "    # 基本帧索引计算\n",
    "    frame_indices = np.floor(timestamps * fps).astype(int)\n",
    "    \n",
    "    # 可选：确保帧索引连续(无重复)\n",
    "    unique_indices = []\n",
    "    last_index = -1\n",
    "    \n",
    "    for idx in frame_indices:\n",
    "        if idx > last_index:\n",
    "            unique_indices.append(idx)\n",
    "            last_index = idx\n",
    "        else:\n",
    "            # 如果遇到重复或倒退的索引，递增处理\n",
    "            unique_indices.append(last_index + 1)\n",
    "            last_index += 1\n",
    "            \n",
    "    episodes[episode_num][\"frame_index\"] = unique_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f713e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf731e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd382cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for episode_num, episode_df in episodes.items():\n",
    "    episode_df[['action', 'observation.state', 'timestamp', 'frame_index', 'episode_index', 'index', 'task_index']].reset_index().to_parquet(f'demo_data/elephant_robot/data/chunk-000/episode_{episode_num:06d}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc14c00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gr00t.utils.misc import any_describe\n",
    "from gr00t.data.dataset import LeRobotSingleDataset\n",
    "from gr00t.experiment.data_config import DATA_CONFIG_MAP\n",
    "\n",
    "dataset_path = \"./demo_data/elephant_robot\"   # change this to your dataset path\n",
    "\n",
    "data_config = DATA_CONFIG_MAP[\"elephant_robot\"]\n",
    "\n",
    "dataset = LeRobotSingleDataset(\n",
    "    dataset_path=dataset_path,\n",
    "    modality_configs=data_config.modality_config(),\n",
    "    embodiment_tag=\"new_embodiment\",\n",
    "    video_backend=\"torchvision_av\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8919cfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = dataset[7]\n",
    "any_describe(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fba270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the dataset\n",
    "# show img\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "images_list = []\n",
    "\n",
    "for i in range(10):\n",
    "    resp = dataset[i]\n",
    "    img = resp[\"video.webcam\"][0]\n",
    "    images_list.append(img)\n",
    "\n",
    "fig, axs = plt.subplots(2, 5, figsize=(20, 10))\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.imshow(images_list[i])\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(f\"Image {i}\")\n",
    "plt.tight_layout() # adjust the subplots to fit into the figure area.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3356f1",
   "metadata": {},
   "source": [
    "```\n",
    "python scripts/gr00t_finetune.py \\\n",
    "   --dataset-path getting_started/demo_data/elephant_robot/ \\\n",
    "   --num-gpus 1 \\\n",
    "   --batch_size 16 \\\n",
    "   --dataloader_num_workers 8 \\\n",
    "   --output-dir ~/elephant_robot-checkpoints  \\\n",
    "   --max-steps 2000 \\\n",
    "   --data-config elephant_robot \\\n",
    "   --video-backend torchvision_av\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e96489",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gr00t",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
